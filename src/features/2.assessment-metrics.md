# Assessment Metrics

Assessment Metrics is used to allow admin configuring custom metrics for an assessment to see the answers in a proper way.

## New DB Table

### `analytics_metrics`

* `id` id of this metrics
* `name` the name of this metrics
* `description` the description of this metrics
* `is_public` whether this is a public metrics in the metrics library
* `data_source` : which data source we are linking to for the calculation
  * For MVP, we only support `question`
* `data_type` defines how to link to an assessment question. It has the following valid value (MVP):
  * `scalar` : can only be linked to a radio button choice question of an assessment
* `aggregation` defines how to calculate the result. It has the following valid value: (when the `data_type` is `scalar`)
  * `average` : the result will be the average `weight` of the answers for this question
  * `sum` : the result will be the sum of the `weight` of the answers for this question
  * `count` : the result will be the count of the user that has answered that question
* `filter_type` : the type of filter. Valid value `role` (MVP)
* `filter_value` : the filter value.
  * When `filter_type` is `role`, the valid values are `participant, mentor, coordinator, admin`
* `default_calculation_frequency`

### `analytics_metrics_institutions`

Relationship between a metrics and an institution

* `id`
* `metrics_id`
* `institution_id`
* `requirement` has the following valid value:
  * `required` : without linking this metrics to an assessment, an experience can not go live
  * `recommanded` : an experience can go live without linking this metrics to an assessment, but there will be a warning
  * `not required` : an experience can go live without linking this metrics to an assessment
* `status`
  * `draft` : won't show on the experience page
  * `active` : show on the experience page
  * `archived` : won't show on the experience page

### `analytics_metrics_links`

Relationship between a metrics and a data source link in an experience

* `id`
* `metrics_id`
* `data_source_id` : the related data source id
  * When `data_source` = `question`, this id is the question id
* `experience_id`
* `institution_id`
* `calculation_frequency` : when to calculate the metrics
  * `on demand` : we only support on demand calculation for MVP

### `analytics_metrics_records`

The table to store the metrics report records

* `id`
* `metrics_question_id`
* `value` : metrics data value result
* `count` : how many data have we gone through to do the calculation
* `created` : date when the record gets calculated

## Workflow

### Create metrics

There will be a page on the institution level to see all the required/recommanded metrics and institution admin is able to create new metrics or use a metrics from the metrics library.

### Use metrics

On the experience dashboard, there will be a "metrics" tab. Admin can link metrics to a specific assessment question or add a new metrics.

If a `required` metrics is not linked to an assessment question, it will display a red border. The experience can't go live if there are `required` metrics haven't linking to an assessment question.

If a `recommanded` metrics is not linked to an assessment question, it will display an orange border

### Trigger metrics calculation

On MVP, we will only implement on demand calculation. There will be a button in the experience dashboard "metrics" tab to trigger the calculation

### Export metrics result report

There will be a button in the experience dashboard "metrics" tab to export the report CSV

* We need to define the format of the report CSV

## Tasks

1. Create new db tables **[API]**
2. List all the metrics in the institution *(institution setting page)*
   1. Page for the list **[UI]**
   2. API for the list **[API]**
3. Add a new metrics *(institution setting page)*
   1. Add a fresh new metrics from a form **[UI]**
   2. API to create a new metrics with form data **[API]**
   3. Add a new metrics from the metrics library
      1. List the metrics in the library **[UI]**
      2. API to list the metrics in the library **[API]**
      3. API to add a new metrics with a given metrics id from library **[API]**
4. Edit metrics *(institution setting page)*
   1. Page to edit metrics **[UI]**
   2. API to edit metrics **[API]**
5. List all the metrics in the institution *(experience setting page)*
   1. Page for the list (indicate whether each metrics is configured or not) **[UI]**
   2. API for the list (including the configuration in the experience) **[API]**
6. Configure a metrics in the experience. i.e. link a metrics to an assessment question *(experience setting page)*
   1. Page to link metrics to a question (inside an experience) **[UI]**
   2. API to list assessment questions **[API]**
   3. API to link metrics to a question **[API]**
7. Trigger the calculation *(experience setting page)*
   1. A button to trigger the calculation **[UI]**
   2. API to do the calculation **[API]**
8. Download the report CSV *(experience setting page)*
   1. A button to download the report CSV **[UI]**
   2. API to respond with report data **[API]**
