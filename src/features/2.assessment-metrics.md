# Assessment Metrics

Assessment Metrics is used to allow admin configuring custom metrics for an assessment to see the answers in a proper way.

## New DB Table

### `analytics_metrics`

* `id` id of this metrics
* `name` the name of this metrics
* `description` the description of this metrics
* `is_public` whether this is a public metrics in the metrics library
* `data_type` defines how to link to an assessment question. It has the following valid value (MVP):
  * `scalar` : can only be linked to a radio button choice question of an assessment
* `aggregation` defines how to calculate the result. It has the following valid value: (when the `data_type` is `scalar`)
  * `first` : the result will be the `weight` of the first answer for this question
  * `last` : the result will be the `weight` of the last answer for this question
  * `min` : the result will be the mininum `weight` of the answers for this question
  * `max` : the result will be the maximum `weight` of the answers for this question
  * `average` : the result will be the average `weight` of the answers for this question
  * `sum` : the result will be the sum of the `weight` of the answers for this question
* `filter_type` : the type of filter. Valid value `role` (MVP)
* `filter_value` : the filter value.
  * When `filter_type` is `role`, the valid values are `participant, mentor, coordinator, admin`
* `default_calculation_frequency`

### `analytics_metrics_institutions`

Relationship between a metrics and an institution

* `id`
* `metrics_id`
* `institution_id`
* `requirement` has the following valid value:
  * `required` : without linking this metrics to an assessment, an experience can not go live
  * `recommanded` : an experience can go live without linking this metrics to an assessment, but there will be a warning
  * `not required` : an experience can go live without linking this metrics to an assessment
* `status`
  * `draft` : won't show on the experience page
  * `active` : show on the experience page
  * `archived` : won't show on the experience page

### `analytics_metrics_questions`

Relationship between a metrics and a question in an experience

* `id`
* `metrics_id`
* `question_id`
* `experience_id`
* `institution_id`
* `calculation_frequency` : when to calculate the metrics
  * `on demand` : we only support on demand calculation for MVP

### `analytics_metrics_records`

The table to store the metrics report records

* `id`
* `metrics_question_id`
* `value` : metrics data value result
* `data_points` : how many data points are used to generate this metrics record
* `created` : date when the record gets calculated

## Workflow

### Create metrics

There will be a page on the institution level to see all the required/recommanded metrics and institution admin is able to create new metrics or use a metrics from the metrics library.

### Use metrics

On the experience dashboard, there will be a "metrics" tab. Admin can link metrics to a specific assessment question or add a new metrics.

If a `required` metrics is not linked to an assessment question, it will display a red border. The experience can't go live if there are `required` metrics haven't linking to an assessment question.

If a `recommanded` metrics is not linked to an assessment question, it will display an orange border

### Trigger metrics calculation

On MVP, we will only implement on demand calculation. There will be a button in the experience dashboard "metrics" tab to trigger the calculation

### Export metrics result report

There will be a button in the experience dashboard "metrics" tab to export the report CSV

* We need to define the format of the report CSV

## Tasks

1. Create new db tables
2. Create the page to list all the metrics in the current institution
3. Create the UI to add a new metrics
4. Create the page for admin to link metrics to an assessment question
5. Create the UI to allow admin trigger the calculation
6. Create the UI to allow admin download the report CSV
